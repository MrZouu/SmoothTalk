{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5b07c32d",
      "metadata": {
        "id": "5b07c32d"
      },
      "source": [
        "# Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders matplotlib opencv-python spicy"
      ],
      "metadata": {
        "id": "hB7qUUnp9Pbr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d4ead37-50b4-49ac-fc21-e8fa54093b3f"
      },
      "id": "hB7qUUnp9Pbr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Collecting spicy\n",
            "  Downloading spicy-0.16.0-py2.py3-none-any.whl (1.7 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from spicy) (1.11.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Installing collected packages: split-folders, spicy\n",
            "Successfully installed spicy-0.16.0 split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "932bdfe4",
      "metadata": {
        "id": "932bdfe4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import transforms, models, datasets\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from tqdm import tqdm # Afficher entrainement en temps reel\n",
        "import matplotlib.pyplot as plt # Dessiner graphes\n",
        "import os\n",
        "import zipfile #Intégrer fichier zip du drive\n",
        "import splitfolders\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "from google.colab import files\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55257c35",
      "metadata": {
        "id": "55257c35",
        "outputId": "ba81f7e8-b53f-40ec-a5bf-f123f6d1fabd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e92fd0d",
      "metadata": {
        "id": "7e92fd0d"
      },
      "outputs": [],
      "source": [
        "# Placer le dataset dans son drive au format zip\n",
        "zip_train = zipfile.ZipFile('/content/drive/MyDrive/dataset.zip', 'r')\n",
        "zip_train.extractall('/tmp')\n",
        "zip_train.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4819e4d",
      "metadata": {
        "id": "b4819e4d"
      },
      "source": [
        "# Pré-Traitement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "822321db",
      "metadata": {
        "id": "822321db"
      },
      "outputs": [],
      "source": [
        "# Définir la transformation des données\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # Normalisation des valeurs de pixel centré autour de 0 (-1 ; 1)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d740beb",
      "metadata": {
        "id": "3d740beb"
      },
      "source": [
        "# Charger données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54d2c99a",
      "metadata": {
        "id": "54d2c99a"
      },
      "outputs": [],
      "source": [
        "# Définir le chemin vers le dossier contenant le dataset\n",
        "data_path = '/tmp/DATA'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdb2f74c",
      "metadata": {
        "id": "bdb2f74c"
      },
      "outputs": [],
      "source": [
        "# Charger le jeu de données ASL Alphabet\n",
        "asl_dataset = datasets.ImageFolder(root=data_path, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ede0e1b5",
      "metadata": {
        "id": "ede0e1b5"
      },
      "outputs": [],
      "source": [
        "# Diviser le jeu de données en ensembles d'entraînement et de test\n",
        "dataset_size = len(asl_dataset)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "test_size = dataset_size - train_size\n",
        "train_dataset, test_dataset = random_split(asl_dataset, [train_size, test_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbcade04",
      "metadata": {
        "id": "cbcade04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52580ad3-f211-4fe2-c571-48b5f4e4d8c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "# Définir les chargeurs de données\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b5c163d",
      "metadata": {
        "id": "1b5c163d"
      },
      "source": [
        "# Resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5cc60ca",
      "metadata": {
        "id": "e5cc60ca"
      },
      "outputs": [],
      "source": [
        "class ResNet50(nn.Module):\n",
        "    def __init__(self, num_classes, weights=None):\n",
        "        super(ResNet50, self).__init__()\n",
        "        # Charger le modèle pré-entraîné ResNet50\n",
        "        self.resnet = resnet50(pretrained=True if weights is None else False)\n",
        "\n",
        "        # Extraire les couches sauf la couche de classification finale (dernière couche)\n",
        "        self.features = nn.Sequential(*list(self.resnet.children())[:-1])\n",
        "\n",
        "        # Ajouter une nouvelle couche de classification adaptée au nombre de classes (26 lettres)\n",
        "        self.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "603a2c9c",
      "metadata": {
        "id": "603a2c9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9509c7f7-c9c8-4f29-a2ad-aad110d90ff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Instancier le modèle ResNet50, la fonction de coût et l'optimiseur\n",
        "num_classes = 26  # Nombre de classes correspondant aux lettres de l'alphabet\n",
        "# model = ResNet50(num_classes, weights=None).to(device)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Sélectionner automatiquement le dispositif disponible\n",
        "model = ResNet50(num_classes, weights=ResNet50_Weights.DEFAULT).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "446ca48a",
      "metadata": {
        "id": "446ca48a"
      },
      "source": [
        "# Entrainement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2df39f43",
      "metadata": {
        "id": "2df39f43"
      },
      "outputs": [],
      "source": [
        "# Entraîner le modèle\n",
        "num_epochs = 13\n",
        "\n",
        "# Initialiser les listes pour stocker les statistiques d'entraînement\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "class_precisions = []\n",
        "class_recalls = []\n",
        "class_f1_scores = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e34b507",
      "metadata": {
        "id": "8e34b507",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3607a34e-8d9d-4376-b1de-791538f68e02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/12:  52%|█████▏    | 348/672 [07:31<06:57,  1.29s/it, accuracy=32.45%, loss=2.255]"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False, position=0, dynamic_ncols=True)\n",
        "\n",
        "    for batch_idx, (inputs, labels) in enumerate(progress_bar):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        progress_bar.set_postfix(loss=f'{running_loss / (batch_idx + 1):.3f}', accuracy=f'{100 * correct / total:.2f}%')\n",
        "\n",
        "    # Imprimer la statistique de l'ensemble d'entraînement à la fin de l'époque\n",
        "    average_loss = running_loss / len(train_loader)\n",
        "    accuracy = correct / total\n",
        "    train_losses.append(average_loss)\n",
        "    train_accuracies.append(accuracy)\n",
        "    progress_bar.set_postfix(loss=f'{average_loss:.3f}', accuracy=f'{100 * accuracy:.2f}%')\n",
        "    progress_bar.close()  # Fermer la barre de progression à la fin de l'époque\n",
        "\n",
        "    # Tester le modèle sur les données de test après chaque époque\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predicted = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predicted.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Enregistrer la précision des tests\n",
        "    test_accuracy = correct / total\n",
        "    test_accuracies.append(test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, f1_score, _ = precision_recall_fscore_support(all_labels, all_predicted, average=None)\n",
        "class_precisions.append(precision)\n",
        "class_recalls.append(recall)\n",
        "class_f1_scores.append(f1_score)\n",
        "\n",
        "# Afficher les métriques par classe\n",
        "for i, (precision, recall, f1_score) in enumerate(zip(class_precisions[-1], class_recalls[-1], class_f1_scores[-1])):\n",
        "    print(f\"Class {i}: Precision={precision:.4f}, Recall={recall:.4f}, F1-Score={f1_score:.4f}\")"
      ],
      "metadata": {
        "id": "3qHsm_TTM6p0"
      },
      "id": "3qHsm_TTM6p0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1e49568e",
      "metadata": {
        "id": "1e49568e"
      },
      "source": [
        "# Graphes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8689a17e",
      "metadata": {
        "id": "8689a17e"
      },
      "outputs": [],
      "source": [
        "# Tracer les courbes d'entraînement\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Courbe de perte\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "# Courbe d'exactitude\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label='Train Accuracy', marker='o')\n",
        "plt.plot(test_accuracies, label='Test Accuracy', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Test Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d535f2b2",
      "metadata": {
        "id": "d535f2b2"
      },
      "source": [
        "# Enregistrement du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6d465bb",
      "metadata": {
        "id": "a6d465bb"
      },
      "outputs": [],
      "source": [
        "# Enregistrer le modèle à la fin de l'entraînement\n",
        "torch.save(model.state_dict(), 'pytorch_model.pth')\n",
        "print(\"Le modèle a été enregistré.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e98f150",
      "metadata": {
        "id": "4e98f150"
      },
      "outputs": [],
      "source": [
        "files.download('pytorch_model.pth')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}